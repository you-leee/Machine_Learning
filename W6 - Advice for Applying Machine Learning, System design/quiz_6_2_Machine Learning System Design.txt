1.) You are working on a spam classification system using regularized logistic regression. "Spam" is a positive class (y = 1) and "not spam" is the negative class (y = 0). You have trained your classifier and there are m = 1000 examples in the cross-validation set. The chart of predicted class vs. actual class is:
				Actual 1	Actual 0
Predicted 1		85			890
Predicted 0		15			10

For reference:
    Accuracy = (true positives + true negatives) / (total examples)
    Precision = (true positives) / (true positives + false positives)
    Recall = (true positives) / (true positives + false negatives)
    F1 score = (2 * precision * recall) / (precision + recall)

What is the classifier's precision (as a value from 0 to 1)?
	- 85/(85+890) = 85/975 = 0.08717948..
	
	
2.)  Suppose a massive dataset is available for training a learning algorithm. Training on a lot of data is likely to give good performance when two of the following conditions hold true.
Which are the two?
	- Our learning algorithm is able to represent fairly complex functions (for example, if we train a neural network or other model with a large number of parameters).
	- A human expert on the application domain can confidently predict y when given only the features x (or more generally, if we have some way to be confident that x contains sufficient information to predict y accurately).

	
3.1.)  Suppose you have trained a logistic regression classifier which is outputing hθ(x). Currently, you predict 1 if hθ(x)≥threshold, and predict 0 if hθ(x)<threshold, where currently the threshold is set to 0.5.
Suppose you decrease the threshold to 0.3. Which of the following are true? Check all that apply.
	- The classifier is likely to now have lower precision.
	
3.2.)  Suppose you have trained a logistic regression classifier which is outputing hθ(x). Currently, you predict 1 if hθ(x)≥threshold, and predict 0 if hθ(x)<threshold, where currently the threshold is set to 0.5.
Suppose you increase the threshold to 0.7. Which of the following are true? Check all that apply.
	- The classifier is likely to now have lower recall.
	
4.)  Suppose you are working on a spam classifier, where spam emails are positive examples (y=1) and non-spam emails are negative examples (y=0). You have a training set of emails in which 99% of the emails are non-spam and the other 1% is spam. 
Which of the following statements are true? Check all that apply.
	- If you always predict non-spam (output y=0), your classifier will have a recall of 0%.
	- If you always predict non-spam (output y=0), your classifier will have an accuracy of 99%.
	- If you always predict spam (output y=1), your classifier will have a recall of 100% and precision of 1%.
	- A good classifier should have both a high precision and high recall on the cross validation set. ??? not sure
	
	
5.) Which of the following statements are true? Check all that apply.
	- Using a very large training set makes it unlikely for model to overfit the training data.
	- On skewed datasets (e.g., when there are more positive examples than negative examples), accuracy is not a good measure of performance and you should instead use F1 score based on the precision and recall.
	